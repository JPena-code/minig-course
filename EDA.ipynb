{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules\n",
    "This section imports the required modules and prepare the raw content of the file in the desired\n",
    "data type for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import pycountry\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "pio.templates.default = 'plotly_dark'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv file zipped\n",
    "zip_path = './data/human-trafficking-victims-dataset-ctdc.zip'\n",
    "data_file = None\n",
    "raw_data = None\n",
    "with ZipFile(zip_path) as zip_file:\n",
    "    for compressed in zip_file.filelist:\n",
    "        if compressed.filename.endswith('csv'):\n",
    "            with zip_file.open(compressed) as data_file:\n",
    "                raw_data = pd.read_csv(\n",
    "                    data_file,\n",
    "                    sep=';',\n",
    "                    header=0,\n",
    "                    low_memory=False,\n",
    "                    usecols=range(1,64),)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data type conversion\n",
    "Conversion of attributes read as the default string type value read from raw data to Categorical object of pandas</br>\n",
    "to simplify the operations for those categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting values of categorical attribute\n",
    "# for performance at processing time\n",
    "# Age numerical categories\n",
    "age_range = [\n",
    "    '0--8',\n",
    "    '9--17',\n",
    "    '18--20',\n",
    "    '21--23',\n",
    "    '24--26',\n",
    "    '27--29',\n",
    "    '30--38',\n",
    "    '39--47',\n",
    "    '48+'\n",
    "]\n",
    "# Gender categories\n",
    "gender_values = [\n",
    "    'Male',\n",
    "    'Female',\n",
    "    'Transgender/NonConforming',\n",
    "]\n",
    "# Age status categories\n",
    "age_cate = [\n",
    "    'Adult',\n",
    "    'Minor',\n",
    "]\n",
    "# Data recorders categories\n",
    "data_source = [\n",
    "    'Case Management',\n",
    "    'Hotline'\n",
    "]\n",
    "# Categorical pandas objects\n",
    "age_cat_range = CategoricalDtype(categories=age_range, ordered=True)\n",
    "gender_cat = CategoricalDtype(categories=gender_values, ordered=False)\n",
    "age_cat = CategoricalDtype(categories=age_cate, ordered=True)\n",
    "data_cat_source = CategoricalDtype(categories=data_source, ordered=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all values read as float due to NaN\n",
    "raw_data = raw_data.apply(lambda series: series.astype('Int32', errors='ignore'))\n",
    "# Convert to categorical types\n",
    "raw_data['Datasource'] = raw_data['Datasource'].astype(data_cat_source)\n",
    "raw_data['gender'] = raw_data['gender'].astype(gender_cat)\n",
    "raw_data['ageBroad'] = raw_data['ageBroad'].astype(age_cat_range)\n",
    "\n",
    "columns_majority = ['majorityStatus', 'majorityStatusAtExploit', 'majorityEntry']\n",
    "raw_data[columns_majority] = raw_data[columns_majority].astype(age_cat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical objects attributes\n",
    "categorical_columns = [\n",
    "    'ageBroad',\n",
    "    'Datasource',\n",
    "    'gender',\n",
    "    'majorityStatus',\n",
    "    'majorityStatusAtExploit',\n",
    "    'majorityEntry']\n",
    "\n",
    "# Categorical countries\n",
    "country_columns = [\n",
    "    'citizenship',\n",
    "    'CountryOfExploitation']\n",
    "\n",
    "# Concatenated categorical categories\n",
    "concatenated_columns = [\n",
    "    'meansOfControlConcatenated',\n",
    "    'typeOfExploitConcatenated',\n",
    "    'typeOfLabourConcatenated',\n",
    "    'typeOfSexConcatenated',\n",
    "    'RecruiterRelationship']\n",
    "\n",
    "# Function to convert country to any ISO country format\n",
    "def country_conversion(country, code='numeric'):\n",
    "    try:\n",
    "        return getattr(pycountry.countries.lookup(country), code)\n",
    "    except LookupError:\n",
    "        # It is a missing data and cannot be convert 'NaN'\n",
    "        # value of country to numeric code\n",
    "        return -1 if code == 'numeric' else 'Unknown'\n",
    "    except ArithmeticError as att:\n",
    "        # In case of the code requested is wrong\n",
    "        raise ArithmeticError(\n",
    "            f'The City object from \"pycountry\" does not have Attribute {code}') from att\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_permutation = raw_data[columns_majority].value_counts(dropna=False).reset_index()#.sort_values(columns_majority)\n",
    "# Index of records can be complete 6, 5, 2, 8, 3, 15, 11, 16, 9, 17\n",
    "# Index of incongruent records combination 19, 18, 21\n",
    "majority_permutation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Incongruente due to anonymization\n",
    "# Total of records to drop 12\n",
    "indexes = [\n",
    "    # majorityStatus = Adult  majorityStatusAtExploit = Minor\tmajorityEntry = Adult\n",
    "    raw_data.query('majorityStatus == @age_cate[0] & majorityStatusAtExploit == @age_cate[1] & majorityEntry == @age_cate[0]').index,\n",
    "    # majorityStatus = Minor  majorityStatusAtExploit = NaN\tmajorityEntry = Adult\n",
    "    raw_data.query('majorityStatus == @age_cate[1] & majorityStatusAtExploit.isna() & majorityEntry == @age_cate[0]').index,\n",
    "    # majorityStatus = NaN  majorityStatusAtExploit = Minor\tmajorityEntry = Adult\n",
    "    raw_data.query('majorityStatus.isna() & majorityStatusAtExploit == @age_cate[1] & majorityEntry == @age_cate[0]').index,\n",
    "]\n",
    "\n",
    "drop_index = pd.Index([])\n",
    "for index in indexes:\n",
    "    drop_index = drop_index.join(index, how='outer')\n",
    "raw_data.drop(drop_index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completing missing data due to anonymization\n",
    "# Total of records to fill 26778\n",
    "indexes = [\n",
    "    # majorityStatus = Adult  majorityStatusAtExploit = Minor\tmajorityEntry = NaN\n",
    "    (raw_data.query('majorityStatus == @age_cate[0] & majorityStatusAtExploit == @age_cate[1] & majorityEntry.isna()').index, 'Minor', 'majorityEntry'),\n",
    "    # majorityStatus = Adult  majorityStatusAtExploit = NaN\tmajorityEntry = Adult\n",
    "    (raw_data.query('majorityStatus == @age_cate[0] & majorityStatusAtExploit.isna() & majorityEntry == @age_cate[0]').index, 'Adult', 'majorityStatusAtExploit'),\n",
    "    # majorityStatus = Minor  majorityStatusAtExploit = Minor\tmajorityEntry = NaN\n",
    "    (raw_data.query('majorityStatus == @age_cate[1] & majorityStatusAtExploit == @age_cate[1] & majorityEntry.isna()').index, 'Minor', 'majorityEntry'),\n",
    "    # majorityStatus = Minor  majorityStatusAtExploit = NaN\tmajorityEntry = Minor\n",
    "    (raw_data.query('majorityStatus == @age_cate[1] & majorityStatusAtExploit.isna() & majorityEntry == @age_cate[1]').index, 'Minor', 'majorityStatusAtExploit'),\n",
    "    # majorityStatus = Minor  majorityStatusAtExploit = NaN\tmajorityEntry = NaN\n",
    "    (raw_data.query('majorityStatus == @age_cate[1] & majorityStatusAtExploit.isna() & majorityEntry.isna()').index, 'Minor', ['majorityStatusAtExploit', 'majorityEntry']),\n",
    "\n",
    "    # majorityStatus = NaN  majorityStatusAtExploit = Adult\tmajorityEntry = Adult\n",
    "    (raw_data.query('majorityStatus.isna() & majorityStatusAtExploit == @age_cate[0] & majorityEntry == @age_cate[0]').index, 'Adult', 'majorityStatus'),\n",
    "    # majorityStatus = NaN  majorityStatusAtExploit = Adult\tmajorityEntry = NaN\n",
    "    (raw_data.query('majorityStatus.isna() & majorityStatusAtExploit == @age_cate[0] & majorityEntry.isna()').index, 'Adult', ['majorityStatus', 'majorityEntry']),\n",
    "    # majorityStatus = NaN  majorityStatusAtExploit = Minor\tmajorityEntry = Minor\n",
    "    (raw_data.query('majorityStatus.isna() & majorityStatusAtExploit == @age_cate[1] & majorityEntry == @age_cate[1]').index, 'Minor', 'majorityStatus'),\n",
    "    # majorityStatus = NaN  majorityStatusAtExploit = Minor\tmajorityEntry = NaN\n",
    "    (raw_data.query('majorityStatus.isna() & majorityStatusAtExploit == @age_cate[1] & majorityEntry.isna()').index, 'Minor', ['majorityStatus', 'majorityEntry']),\n",
    "    # majorityStatus = NaN  majorityStatusAtExploit = NaN\tmajorityEntry = Adult\n",
    "    (raw_data.query('majorityStatus.isna() & majorityStatusAtExploit.isna() & majorityEntry == @age_cate[0]').index, 'Adult', ['majorityStatus', 'majorityEntry']),\n",
    "]\n",
    "\n",
    "for index, value, columns in indexes:\n",
    "    raw_data.loc[index, columns] = value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory analysis\n",
    "Statistical exploratory analysis for the raw dataset, the objective of this first step is discover basic overview of the behavior,</br>\n",
    "trend, relationships, missing and duplicated values. In addition to this, graphic presentations will be used for the better</br>\n",
    "understanding the attributes of dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The data-set has a total of records and attributes {raw_data.shape}\\n')\n",
    "print('Count total of data types in data-set')\n",
    "unique_types = raw_data.dtypes.value_counts()\n",
    "print(unique_types.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN values per record in data-set\n",
    "nan_record = raw_data.isna().sum(axis=1).describe()\n",
    "print('Missing \"NaN\" attributes per record')\n",
    "print(nan_record.to_string(header=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN values per attribute in data-set\n",
    "nan_attribute = raw_data.select_dtypes(exclude=['O']).isna().sum()\n",
    "ratio_nan = nan_attribute / raw_data.shape[0]\n",
    "print('Ratio of missing values in attributes', ratio_nan.to_string(), sep='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Given the nature of the dataset, the possible duplicated records are due to the anonymize preprocessed that was made it by the _CTDC_**</br>\n",
    "and there are not going to be removed from the dataset, for the possible information that those records can subscribe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = raw_data.duplicated().sum()\n",
    "ration_dup = duplicates / raw_data.shape[0]\n",
    "print(f'Total of elements duplicated: {duplicates}\\nRatio of all dataset: {ration_dup:.2%}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Types\n",
    "\n",
    "There are two type of attributes in the data set, _nominal_ and _numeric_.\n",
    "\n",
    "The _numeric_ attributes are mostly _ordinal_ binary used to represent if the attribute is present in a record, on the other side,</br> _nominal_ attributes where converted to a __Categorical__ data type of the package of _pandas_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric attributes description\n",
    "raw_data.describe(exclude=['category', 'O'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nominal attributes\n",
    "raw_data.describe(include=['category'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots\n",
    "Graphical description of the attributes and the relations between each other, the plot used to describe the data are _bar_, _heatmap_, _box_ and _pie_</br>\n",
    "The objective is observe potential trends, frequencies and relationships between the attributes of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_raw = raw_data[country_columns[0]].dropna().apply(country_conversion, code='alpha_3')\n",
    "map_raw = map_raw.value_counts().reset_index(name='records')\n",
    "map_raw.sort_values('records', ascending=False)\n",
    "fig = px.choropleth(\n",
    "    map_raw,\n",
    "    locations=country_columns[0],\n",
    "    color='records',\n",
    "    hover_name=map_raw[country_columns[0]].apply(country_conversion, code='name'),\n",
    "    hover_data={\n",
    "        'citizenship': False,\n",
    "    },\n",
    "    color_continuous_scale=\"burgyl\",\n",
    "    projection='natural earth',\n",
    "    title='Heatmap<br>Citizenship',\n",
    "    template='plotly_white'\n",
    ")\n",
    "fig.update_layout(\n",
    "    height=600,\n",
    "    width=1000,)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heat map of the country where exploitations occur\n",
    "map_raw = raw_data[country_columns[1]].dropna().apply(country_conversion, code='alpha_3')\n",
    "map_raw = map_raw.value_counts().reset_index(name='records')\n",
    "map_raw.sort_values('records', ascending=False)\n",
    "\n",
    "fig = px.choropleth(\n",
    "    map_raw,\n",
    "    locations=country_columns[1],\n",
    "    color='records',\n",
    "    hover_name=map_raw[country_columns[1]].apply(country_conversion, code='name'),\n",
    "    hover_data={\n",
    "        'CountryOfExploitation': False,\n",
    "    },\n",
    "    color_continuous_scale='burgyl',\n",
    "    projection='natural earth',\n",
    "    title='Heatmap<br>Country of explotation',\n",
    "    template='plotly_white'\n",
    ")\n",
    "fig.update_layout(\n",
    "    height=600,\n",
    "    width=1000,)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender of the individuals group by the registration year\n",
    "gender_frequency = raw_data[['yearOfRegistration', 'gender']].groupby(\n",
    "    ['yearOfRegistration', 'gender']).size().reset_index(level=1, name='count')\n",
    "# Area bar per year\n",
    "gender_area = px.area(\n",
    "    gender_frequency,\n",
    "    x=gender_frequency.index,\n",
    "    y='count',\n",
    "    color='gender',\n",
    "    title='Records registered per Year<br>Group by <i>gender<i>',\n",
    "    hover_name=gender_frequency.index,\n",
    "    hover_data={\n",
    "        'gender': False\n",
    "    },\n",
    "    labels={'yearOfRegistration': 'Year', 'count': 'Total/Year'},\n",
    "    category_orders={'gender': ['Transgender/NonConforming', 'Male', 'Female']},)\n",
    "\n",
    "gender_area.update_traces(\n",
    "    hovertemplate='<b>%{hovertext}</b><br><br>Total records: %{y}')\n",
    "gender_area.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the gender of the records\n",
    "gender_count = raw_data['gender'].value_counts(dropna=False).reset_index(name='count')\n",
    "# Pie plot\n",
    "gender_pie = px.pie(\n",
    "    gender_count,\n",
    "    names='gender',\n",
    "    values='count',\n",
    "    title='Gender total frequency<br><i>with missing values<i>',\n",
    "    width=800,\n",
    "    hover_name='gender',\n",
    "    hover_data={'gender': False, 'count': False})\n",
    "\n",
    "gender_pie.update_traces(\n",
    "    textinfo='percent+value',\n",
    "    hoverinfo='label+percent')\n",
    "gender_pie.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age broad grouped by the gender of the record\n",
    "broad_gender = raw_data[['gender', 'ageBroad']].copy(deep=True)\\\n",
    "    .groupby(['gender', 'ageBroad'], dropna=False)\\\n",
    "    .size().reset_index(name='count')\n",
    "# Taking into account the missing values in raw data\n",
    "broad_gender[['gender', 'ageBroad']] = broad_gender[['gender', 'ageBroad']].astype('str')\n",
    "broad_gender['gender'].replace('nan', 'Gender Missing', inplace=True)\n",
    "broad_gender['ageBroad'].replace('nan', 'Missing', inplace=True)\n",
    "\n",
    "# Bar plot\n",
    "broad_gender_bar = px.bar(\n",
    "    broad_gender,\n",
    "    x='ageBroad',\n",
    "    y='count',\n",
    "    color='gender',\n",
    "    title='Distribution of <b>age broad</b><br>Group by <i>gender</i>',\n",
    "    text='count',\n",
    "    text_auto='.3s',\n",
    "    hover_name='gender'\n",
    ")\n",
    "broad_gender_bar.update_traces(\n",
    "    hovertemplate='<b>%{hovertext}</b><br><br>Total of records: %{y}<extra></extra>'\n",
    ")\n",
    "broad_gender_bar.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority = raw_data[columns_majority].apply(pd.Series.value_counts).T\\\n",
    "    .unstack().reset_index(name='count')\\\n",
    "    .rename(columns={'level_0': 'majority', 'level_1': 'status'})\n",
    "\n",
    "majority_bar = px.bar(\n",
    "    majority,\n",
    "    x='majority',\n",
    "    y='count',\n",
    "    color='status',\n",
    "    barmode='group',\n",
    "    hover_name='status',\n",
    "    text='count',\n",
    "    text_auto='.2s',\n",
    ")\n",
    "majority_bar.update_traces(\n",
    "    textangle=-45,\n",
    "    textposition='outside',\n",
    "    cliponaxis=False,\n",
    "    hovertemplate='<b>%{hovertext}</b><br><br>Total of records: %{y:d}<extra></extra>'\n",
    ")\n",
    "majority_bar.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_totals = raw_data.filter(regex='(Concatenated|Relationship)$')\n",
    "count_totals = count_totals.applymap(lambda x: len(x.split(';')), na_action='ignore').fillna(0).astype('int32')\n",
    "count_totals.rename(columns=lambda x: re.sub(r'(Concatenated)?$', 'Count', x, count=1), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axis = count_totals.boxplot(\n",
    "    fontsize=8,\n",
    "    grid=False,\n",
    "    figsize=(10, 6),\n",
    "    showcaps=True,\n",
    "    flierprops={'marker': '.', 'markersize': 3},\n",
    "    showmeans=True,\n",
    "    meanline=True,)\n",
    "axis.set_ylim(-1)\n",
    "title = axis.set_title('Total count of subcategories')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axis = count_totals.plot.kde()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomamos las variables cualitativas del dataset junto con las variables que nos sirven como indexación\n",
    "dataset_columns = [ 'yearOfRegistration', 'Datasource', 'gender', 'ageBroad',\n",
    "       'majorityStatus', 'majorityStatusAtExploit', 'majorityEntry',\n",
    "       'citizenship', 'meansOfControlConcatenated','typeOfExploitConcatenated', 'typeOfLabourConcatenated',\n",
    "       'typeOfSexConcatenated', 'isAbduction', 'RecruiterRelationship',\n",
    "       'CountryOfExploitation', 'recruiterRelationIntimatePartner',\n",
    "       'recruiterRelationFriend', 'recruiterRelationFamily',\n",
    "       'recruiterRelationOther', 'recruiterRelationUnknown']\n",
    "\n",
    "# Generamos un nuevo dataset con esta reducción de dimensionalidad\n",
    "new_data_set = raw_data.loc[:,dataset_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = ['meansOfControlConcatenated','typeOfExploitConcatenated', 'typeOfLabourConcatenated',\n",
    "       'typeOfSexConcatenated']\n",
    "\n",
    "\n",
    "new_data_set[columns_to_check] = new_data_set[columns_to_check].replace(0, np.nan)\n",
    "# Filtrar los registros con datos faltantes solo en las columnas mencionadas\n",
    "filtered_data = new_data_set[new_data_set[columns_to_check].isnull().all(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.shape[0] / new_data_set.shape[0] * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular cuántos registros eliminar (90%)\n",
    "num_records_to_delete = int(len(filtered_data) * 0.9)\n",
    "\n",
    "# Eliminar el 90% de los registros sin datos\n",
    "filtered_data = filtered_data.sample(n=num_records_to_delete, random_state=42)\n",
    "\n",
    "# Restaurar los registros eliminados a new_data_set\n",
    "new_data_set = new_data_set[~new_data_set.index.isin(filtered_data.index)]\n",
    "\n",
    "# Imputación de datos faltantes utilizando la moda (valor más común)\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Aplicar la imputación solo a las columnas de interés\n",
    "new_data_set[columns_to_check] = imputer.fit_transform(new_data_set[columns_to_check])\n",
    "\n",
    "# Verificar el resultado\n",
    "print(new_data_set.isnull().sum())\n",
    "\n",
    "# Realizar muestras visuales para verificar la imputación\n",
    "sample_data = new_data_set.sample(10)  # Muestra aleatoria de 10 registros\n",
    "print(sample_data[columns_to_check])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de campos que necesitan one-hot encoding\n",
    "fields_to_encode = ['meansOfControlConcatenated', 'typeOfExploitConcatenated', 'typeOfLabourConcatenated', 'typeOfSexConcatenated']\n",
    "\n",
    "# Itera sobre cada campo y aplica one-hot encoding\n",
    "for field in fields_to_encode:\n",
    "    # Divide el campo en múltiples columnas one-hot\n",
    "    one_hot_encoded = new_data_set[field].str.get_dummies(sep=';')\n",
    "\n",
    "    # Renombra las columnas para que sean únicas\n",
    "    one_hot_encoded.columns = [f\"{field}_{column}\" for column in one_hot_encoded.columns]\n",
    "\n",
    "    # Concatena las columnas one-hot al nuevo dataset\n",
    "    new_data_set = pd.concat([new_data_set, one_hot_encoded], axis=1)\n",
    "\n",
    "# Elimina las columnas originales que ya han sido one-hot encoded\n",
    "new_data_set = new_data_set.drop(fields_to_encode, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_set.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
